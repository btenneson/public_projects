{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load data from the GitHub raw URL\n",
    "url = \"https://raw.githubusercontent.com/btenneson/public_projects/main/Diabetes3.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Load the CSV file from your local directory\n",
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "# data = pd.read_csv(\"g:\\\\My Drive\\\\research\\\\diabetes\\\\Diabetes3.csv\")\n",
    "\n",
    "\n",
    "# Define the objective function to maximize the absolute correlation\n",
    "def objective_function(bias, data):\n",
    "    # Calculate synthetic scores\n",
    "    synthetic_scores = data.iloc[:, 1:].dot(bias)\n",
    "    \n",
    "    # Correlation with the first column\n",
    "    correlation = np.corrcoef(data.iloc[:, 0], synthetic_scores)[0, 1]\n",
    "    \n",
    "    # Minimize the negative absolute correlation\n",
    "    return -abs(correlation)\n",
    "\n",
    "# Initial guess for the bias vector (random values, no need to normalize)\n",
    "n_minus_1 = data.shape[1] - 1  # Assuming data includes the first column\n",
    "initial_bias = np.random.rand(n_minus_1)\n",
    "\n",
    "# Minimization process\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    initial_bias,\n",
    "    args=(data,),\n",
    "    method='Powell',\n",
    "    options={'disp': True}\n",
    ")\n",
    "\n",
    "# Check results\n",
    "if result.success:\n",
    "    optimized_bias = result.x\n",
    "    print(\"Optimized bias vector:\", optimized_bias)\n",
    "    print(\"Achieved correlation:\", -result.fun)  # Negate to show maximized correlation\n",
    "else:\n",
    "    print(\"Optimization failed:\", result.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(optimized_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Assuming 'synthetic_scores' is already calculated and part of your DataFrame\n",
    "X = data['synthetic_scores'].values.reshape(-1, 1)  # Use synthetic scores as features\n",
    "y = data.iloc[:, 0].values  # The target variable\n",
    "\n",
    "# Convert the data into LightGBM dataset format\n",
    "lgb_train = lgb.Dataset(X, label=y)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',  # Assuming the target is binary\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "fitted_scores = gbm.predict(X)\n",
    "\n",
    "# Function to calculate accuracy for a given threshold\n",
    "def calculate_accuracy(threshold):\n",
    "    y_pred = (fitted_scores >= threshold).astype(int)\n",
    "    return accuracy_score(y, y_pred)\n",
    "\n",
    "# Test thresholds from 0.0 to 1.0 in small increments\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "accuracies = [calculate_accuracy(t) for t in thresholds]\n",
    "\n",
    "# Find the threshold with the highest accuracy\n",
    "best_threshold_index = np.argmax(accuracies)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_accuracy = accuracies[best_threshold_index]\n",
    "\n",
    "# Generate predictions using the best threshold\n",
    "best_predicted_labels = (fitted_scores >= best_threshold).astype(int)\n",
    "data['Optimized_Predicted'] = best_predicted_labels\n",
    "\n",
    "# Print results\n",
    "print(f\"Best Threshold: {best_threshold}\")\n",
    "print(f\"Best Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Additional metrics\n",
    "conf_matrix = confusion_matrix(y, best_predicted_labels)\n",
    "f1 = f1_score(y, best_predicted_labels)\n",
    "precision = precision_score(y, best_predicted_labels)\n",
    "recall = recall_score(y, best_predicted_labels)\n",
    "auc = roc_auc_score(y, fitted_scores)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y, fitted_scores)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from the GitHub raw URL\n",
    "url = \"https://raw.githubusercontent.com/btenneson/public_projects/main/Diabetes3.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Load the CSV file from your local directory\n",
    "# Replace 'your_file.csv' with the actual path to your CSV file\n",
    "# data = pd.read_csv(\"g:\\\\My Drive\\\\research\\\\diabetes\\\\Diabetes3.csv\")\n",
    "\n",
    "\n",
    "# Replace NaNs with the mean of the respective columns\n",
    "# data_filled = data.apply(lambda col: col.fillna(col.mean()) if col.dtype in ['float64', 'int64'] else col)\n",
    "# data = data_filled\n",
    "\n",
    "# Define the objective function to maximize the absolute correlation\n",
    "def objective_function(bias, data):\n",
    "    synthetic_scores = data.iloc[:, 1:].dot(bias)\n",
    "    correlation = np.corrcoef(data.iloc[:, 0], synthetic_scores)[0, 1]\n",
    "    return -abs(correlation)\n",
    "\n",
    "# Set the number of iterations (M)\n",
    "user_input = 1  # Adjust this multiplier as needed\n",
    "M = int(0.8 * data.shape[0] * user_input)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Repeat the procedure M times\n",
    "for i in range(M):\n",
    "    print(f\"Iteration {i+1}/{M}\")\n",
    "\n",
    "    # Initial guess for the bias vector (random values)\n",
    "    n_minus_1 = data.shape[1] - 1\n",
    "    initial_bias = np.random.rand(n_minus_1)\n",
    "\n",
    "    # Minimization process\n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        initial_bias,\n",
    "        args=(data,),\n",
    "        method='Powell',\n",
    "        options={'disp': False}  # Set to False to reduce output during multiple runs\n",
    "    )\n",
    "\n",
    "    # Check results\n",
    "    if result.success:\n",
    "        optimized_bias = result.x\n",
    "    else:\n",
    "        print(\"Optimization failed:\", result.message)\n",
    "        continue\n",
    "\n",
    "    # Calculate synthetic scores\n",
    "    synthetic_scores = data.iloc[:, 1:].dot(optimized_bias)\n",
    "    data['synthetic_scores'] = synthetic_scores\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X = data['synthetic_scores'].values.reshape(-1, 1)\n",
    "    y = data.iloc[:, 0].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)  # Different random_state for each iteration\n",
    "\n",
    "    # Convert the training data into LightGBM dataset format\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9\n",
    "    }\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    gbm = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    fitted_scores = gbm.predict(X_test)\n",
    "\n",
    "    # Find the best threshold based on accuracy\n",
    "    thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "    accuracies = [(fitted_scores >= t).astype(int) for t in thresholds]\n",
    "    accuracies = [accuracy_score(y_test, y_pred) for y_pred in accuracies]\n",
    "\n",
    "    best_threshold_index = np.argmax(accuracies)\n",
    "    best_threshold = thresholds[best_threshold_index]\n",
    "    best_predicted_labels = (fitted_scores >= best_threshold).astype(int)\n",
    "\n",
    "    # Calculate and store metrics\n",
    "    accuracy_list.append(accuracies[best_threshold_index])\n",
    "    f1_list.append(f1_score(y_test, best_predicted_labels))\n",
    "    precision_list.append(precision_score(y_test, best_predicted_labels))\n",
    "    recall_list.append(recall_score(y_test, best_predicted_labels))\n",
    "    auc_list.append(roc_auc_score(y_test, fitted_scores))\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nFinal Summary:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_list) * 100:.2f}%\")\n",
    "print(f\"Average F1 Score: {np.mean(f1_list):.2f}\")\n",
    "print(f\"Average Precision: {np.mean(precision_list):.2f}\")\n",
    "print(f\"Average Recall: {np.mean(recall_list):.2f}\")\n",
    "print(f\"Average AUC: {np.mean(auc_list):.2f}\")\n",
    "\n",
    "# Plot ROC Curve for the final iteration\n",
    "fpr, tpr, thresholds = roc_curve(y_test, fitted_scores)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_list[-1])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
